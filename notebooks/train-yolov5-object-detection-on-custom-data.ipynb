{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD9gUQpaBxNa"
      },
      "source": [
        "# How to Train YOLOv5 on Custom Objects\n",
        "\n",
        "This tutorial is based on the [YOLOv5 repository](https://github.com/ultralytics/yolov5) by [Ultralytics](https://www.ultralytics.com/). This notebook shows training on **your own custom objects**. Many thanks to Ultralytics for putting this repository together - we hope that in combination with clean data management tools at Roboflow, this technologoy will become easily accessible to any developer wishing to use computer vision in their projects.\n",
        "\n",
        "### Accompanying Blog Post\n",
        "\n",
        "We recommend that you follow along in this notebook while reading the blog post on [how to train YOLOv5](https://blog.roboflow.ai/how-to-train-yolov5-on-a-custom-dataset/), concurrently.\n",
        "\n",
        "### Steps Covered in this Tutorial\n",
        "\n",
        "In this tutorial, we will walk through the steps required to train YOLOv5 on your custom objects. We use a [public blood cell detection dataset](https://public.roboflow.ai/object-detection/bccd), which is open source and free to use. You can also use this notebook on your own data.\n",
        "\n",
        "To train our detector we take the following steps:\n",
        "\n",
        "* Install YOLOv5 dependencies\n",
        "* Download custom YOLOv5 object detection data\n",
        "* Write our YOLOv5 Training configuration\n",
        "* Run YOLOv5 training\n",
        "* Evaluate YOLOv5 performance\n",
        "* Visualize YOLOv5 training data\n",
        "* Run YOLOv5 inference on test images\n",
        "* Export saved YOLOv5 weights for future inference\n",
        "\n",
        "\n",
        "\n",
        "### **About**\n",
        "\n",
        "[Roboflow](https://roboflow.com) enables teams to deploy custom computer vision models quickly and accurately. Convert data from to annotation format, assess dataset health, preprocess, augment, and more. It's free for your first 1000 source images.\n",
        "\n",
        "**Looking for a vision model available via API without hassle? Try Roboflow Train.**\n",
        "\n",
        "![Roboflow Wordmark](https://i.imgur.com/dcLNMhV.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "#Install Dependencies\n",
        "\n",
        "_(Remember to choose GPU in Runtime if not already selected. Runtime --> Change Runtime Type --> Hardware accelerator --> GPU)_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ie5uLDH4uzAp",
        "outputId": "e033da10-9cbc-4645-8927-c031bed1553e",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 15874, done.\u001b[K\n",
            "remote: Counting objects: 100% (106/106), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 15874 (delta 45), reused 56 (delta 20), pack-reused 15768\u001b[K\n",
            "Receiving objects: 100% (15874/15874), 14.68 MiB | 25.31 MiB/s, done.\n",
            "Resolving deltas: 100% (10857/10857), done.\n",
            "/content/yolov5\n",
            "HEAD is now at 064365d Update parse_opt() in export.py to work as in train.py (#10789)\n"
          ]
        }
      ],
      "source": [
        "# clone YOLOv5 repository\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "!git reset --hard 064365d8683fd002e9ad789c1e91fa3d021b44f0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbvMlHd_QwMG",
        "outputId": "ab6ced34-164a-48e6-c407-9def14fc096f",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hSetup complete. Using torch 2.0.1+cu118 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15101MB, multi_processor_count=40)\n"
          ]
        }
      ],
      "source": [
        "# install dependencies as necessary\n",
        "!pip install -qr requirements.txt  # install dependencies (ignore errors)\n",
        "import torch\n",
        "\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "from utils.downloads import attempt_download  # to download models/datasets\n",
        "\n",
        "# clear_output()\n",
        "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDIhrBF0sPaM"
      },
      "source": [
        "# Download Correctly Formatted Custom Dataset\n",
        "\n",
        "We'll download our dataset from Roboflow. Use the \"**YOLOv5 PyTorch**\" export format. Note that the Ultralytics implementation calls for a YAML file defining where your training and test data is. The Roboflow export also writes this format for us.\n",
        "\n",
        "To get your data into Roboflow, follow the [Getting Started Guide](https://blog.roboflow.ai/getting-started-with-roboflow/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDeebwqS9JbZ"
      },
      "source": [
        "\n",
        "\n",
        "![YOLOv5 PyTorch export](https://i.imgur.com/5vr9G2u.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Knxi2ncxWffW",
        "outputId": "76a2ea65-8c9e-487a-d1d4-27efa2e040a0",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.2-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m762.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi==2022.12.7 (from roboflow)\n",
            "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.0.0)\n",
            "Collecting cycler==0.10.0 (from roboflow)\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting idna==2.10 (from roboflow)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.22.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.7.0.72)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Collecting pyparsing==2.4.7 (from roboflow)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Collecting supervision (from roboflow)\n",
            "  Downloading supervision-0.12.0-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.16)\n",
            "Collecting wget (from roboflow)\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.65.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.1.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.41.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (2.0.12)\n",
            "Requirement already satisfied: opencv-python-headless<5.0.0.0,>=4.8.0.74 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (4.8.0.74)\n",
            "Collecting Pillow>=7.1.2 (from roboflow)\n",
            "  Downloading Pillow-8.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=e33f69457c678e575fc250bae4177c8491cbb7f39105ddf8d8513e40b510cb12\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, python-dotenv, pyparsing, Pillow, idna, cycler, certifi, supervision, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.0\n",
            "    Uninstalling pyparsing-3.1.0:\n",
            "      Successfully uninstalled pyparsing-3.1.0\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.11.0\n",
            "    Uninstalling cycler-0.11.0:\n",
            "      Successfully uninstalled cycler-0.11.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2023.7.22\n",
            "    Uninstalling certifi-2023.7.22:\n",
            "      Successfully uninstalled certifi-2023.7.22\n",
            "Successfully installed Pillow-8.4.0 certifi-2022.12.7 cycler-0.10.0 idna-2.10 pyparsing-2.4.7 python-dotenv-1.0.0 requests-toolbelt-1.0.0 roboflow-1.1.2 supervision-0.12.0 wget-3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "certifi",
                  "cycler",
                  "idna",
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in EtiquetaRicardo1-2 to yolov5pytorch: 100% [13209559 / 13209559] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to EtiquetaRicardo1-2 in yolov5pytorch:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1316/1316 [00:00<00:00, 2802.07it/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"duI2P016ViyIHtg9ER5z\")\n",
        "project = rf.workspace(\"silvia-hernandez01-ustabuca-edu-co\").project(\"etiquetaricardo1\")\n",
        "dataset = project.version(2).download(\"yolov5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug_PhK1oqwQA",
        "outputId": "fa926ad9-e74c-4883-cd37-721a4718afd2",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n"
          ]
        }
      ],
      "source": [
        "%cd /content/yolov5\n",
        "#after following the link above, recieve python code with these fields filled in\n",
        "#from roboflow import Roboflow\n",
        "#rf = Roboflow(api_key=\"YOUR API KEY HERE\")\n",
        "#project = rf.workspace().project(\"YOUR PROJECT\")\n",
        "#dataset = project.version(\"YOUR VERSION\").download(\"yolov5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ3DmmGQztJj",
        "outputId": "a133bb72-6281-4404-845c-5d1850b42fdd",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "names:\n",
            "- cuchara\n",
            "- tenedor\n",
            "nc: 2\n",
            "train: EtiquetaRicardo1-2/train/images\n",
            "val: EtiquetaRicardo1-2/valid/images\n"
          ]
        }
      ],
      "source": [
        "# this is the YAML file Roboflow wrote for us that we're loading into this notebook with our data\n",
        "%cat {dataset.location}/data.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwJx-2NHsYxT"
      },
      "source": [
        "# Define Model Configuration and Architecture\n",
        "\n",
        "We will write a yaml script that defines the parameters for our model like the number of classes, anchors, and each layer.\n",
        "\n",
        "You do not need to edit these cells, but you may."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dOPn9wjOAwwK",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# define number of classes based on YAML\n",
        "import yaml\n",
        "with open(dataset.location + \"/data.yaml\", 'r') as stream:\n",
        "    num_classes = str(yaml.safe_load(stream)['nc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Rvt5wilnDyX",
        "outputId": "8b8386bc-0e05-49a8-c1e0-48a836a0b399",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# parameters\n",
            "nc: 80  # number of classes\n",
            "depth_multiple: 0.33  # model depth multiple\n",
            "width_multiple: 0.50  # layer channel multiple\n",
            "\n",
            "# anchors\n",
            "anchors:\n",
            "  - [10,13, 16,30, 33,23]  # P3/8\n",
            "  - [30,61, 62,45, 59,119]  # P4/16\n",
            "  - [116,90, 156,198, 373,326]  # P5/32\n",
            "\n",
            "# YOLOv5 backbone\n",
            "backbone:\n",
            "  # [from, number, module, args]\n",
            "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
            "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
            "   [-1, 3, C3, [128]],\n",
            "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
            "   [-1, 9, C3, [256]],\n",
            "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
            "   [-1, 9, C3, [512]],\n",
            "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
            "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
            "   [-1, 3, C3, [1024, False]],  # 9\n",
            "  ]\n",
            "\n",
            "# YOLOv5 head\n",
            "head:\n",
            "  [[-1, 1, Conv, [512, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
            "   [-1, 3, C3, [512, False]],  # 13\n",
            "\n",
            "   [-1, 1, Conv, [256, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
            "   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n",
            "\n",
            "   [-1, 1, Conv, [256, 3, 2]],\n",
            "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
            "   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n",
            "\n",
            "   [-1, 1, Conv, [512, 3, 2]],\n",
            "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
            "   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n",
            "\n",
            "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
            "  ]\n"
          ]
        }
      ],
      "source": [
        "#this is the model configuration we will use for our tutorial\n",
        "%cat /content/yolov5/models/yolov5s.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "t14hhyqdmw6O",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#customize iPython writefile so we can write variables\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uDxebz13RdRA",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%writetemplate /content/yolov5/models/custom_yolov5s.yaml\n",
        "\n",
        "# parameters\n",
        "nc: {num_classes}  # number of classes\n",
        "depth_multiple: 0.33  # model depth multiple\n",
        "width_multiple: 0.50  # layer channel multiple\n",
        "\n",
        "# anchors\n",
        "anchors:\n",
        "  - [10,13, 16,30, 33,23]  # P3/8\n",
        "  - [30,61, 62,45, 59,119]  # P4/16\n",
        "  - [116,90, 156,198, 373,326]  # P5/32\n",
        "\n",
        "# YOLOv5 backbone\n",
        "backbone:\n",
        "  # [from, number, module, args]\n",
        "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
        "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
        "   [-1, 3, BottleneckCSP, [128]],\n",
        "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
        "   [-1, 9, BottleneckCSP, [256]],\n",
        "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
        "   [-1, 9, BottleneckCSP, [512]],\n",
        "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
        "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
        "  ]\n",
        "\n",
        "# YOLOv5 head\n",
        "head:\n",
        "  [[-1, 1, Conv, [512, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
        "\n",
        "   [-1, 1, Conv, [256, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
        "   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
        "\n",
        "   [-1, 1, Conv, [256, 3, 2]],\n",
        "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
        "\n",
        "   [-1, 1, Conv, [512, 3, 2]],\n",
        "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
        "\n",
        "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
        "  ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUOiNLtMP5aG"
      },
      "source": [
        "# Train Custom YOLOv5 Detector\n",
        "\n",
        "### Next, we'll fire off training!\n",
        "\n",
        "\n",
        "Here, we are able to pass a number of arguments:\n",
        "- **img:** define input image size\n",
        "- **batch:** determine batch size\n",
        "- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n",
        "- **data:** set the path to our yaml file\n",
        "- **cfg:** specify our model configuration\n",
        "- **weights:** specify a custom path to weights. (Note: you can download weights from the Ultralytics Google Drive [folder](https://drive.google.com/open?id=1Drs_Aiu7xx6S-ix95f9kNsA6ueKRpN2J))\n",
        "- **name:** result names\n",
        "- **nosave:** only save the final checkpoint\n",
        "- **cache:** cache images for faster training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NcFxRcFdJ_O",
        "outputId": "66fec18c-93eb-4396-d3e3-777e66f01cd9",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "2023-08-06 11:17:39.628424: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-08-06 11:17:40.496275: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=, cfg=/content/yolov5/models/yolov5l.yaml, data=/content/yolov5/EtiquetaRicardo1-2/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=yolov5s_results, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 131 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
            "YOLOv5 üöÄ v7.0-72-g064365d Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 22.9MB/s]\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     37695  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "YOLOv5l summary: 368 layers, 46143679 parameters, 46143679 gradients, 108.2 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0005), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/EtiquetaRicardo1-2/train/labels... 453 images, 1 backgrounds, 0 corrupt: 100% 453/453 [00:00<00:00, 1666.29it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov5/EtiquetaRicardo1-2/train/labels.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.2GB ram): 100% 453/453 [00:01<00:00, 407.57it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/EtiquetaRicardo1-2/valid/labels... 142 images, 0 backgrounds, 0 corrupt: 100% 142/142 [00:00<00:00, 358.14it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov5/EtiquetaRicardo1-2/valid/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 142/142 [00:00<00:00, 149.48it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.97 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
            "Plotting labels to runs/train/yolov5s_results/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/yolov5s_results\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/99      4.48G     0.1109    0.02055    0.02923         16        416: 100% 29/29 [00:14<00:00,  2.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  1.72it/s]\n",
            "                   all        142        205    0.00207       0.38    0.00155     0.0004\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/99      5.21G     0.1092    0.02001    0.02855          8        416: 100% 29/29 [00:08<00:00,  3.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.08it/s]\n",
            "                   all        142        205    0.00228      0.429    0.00163   0.000452\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/99      5.21G     0.1066    0.02151    0.02721          8        416: 100% 29/29 [00:08<00:00,  3.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.92it/s]\n",
            "                   all        142        205    0.00211       0.41    0.00154   0.000467\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/99      5.21G     0.1042     0.0209    0.02621         13        416: 100% 29/29 [00:08<00:00,  3.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.11it/s]\n",
            "                   all        142        205    0.00202      0.273    0.00143   0.000357\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/99      5.21G     0.1004    0.02136      0.025         10        416: 100% 29/29 [00:07<00:00,  3.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.19it/s]\n",
            "                   all        142        205    0.00173      0.112    0.00102   0.000258\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/99      5.21G    0.09524    0.02202    0.02212         15        416: 100% 29/29 [00:07<00:00,  3.78it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.19it/s]\n",
            "                   all        142        205   0.000561     0.0976    0.00031   7.38e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/99      5.21G    0.09197    0.02276     0.0181          7        416: 100% 29/29 [00:07<00:00,  3.73it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.51it/s]\n",
            "                   all        142        205     0.0158    0.00488    0.00158   0.000434\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/99      5.21G    0.09081    0.02186    0.01348         15        416: 100% 29/29 [00:08<00:00,  3.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.46it/s]\n",
            "                   all        142        205    0.00252      0.449    0.00253   0.000654\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/99      5.21G    0.09068    0.02259   0.009154         10        416: 100% 29/29 [00:08<00:00,  3.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.44it/s]\n",
            "                   all        142        205    0.00258      0.493    0.00897    0.00214\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/99      5.21G    0.08914    0.02175   0.006097         12        416: 100% 29/29 [00:08<00:00,  3.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.04it/s]\n",
            "                   all        142        205     0.0614      0.112     0.0217    0.00543\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/99      5.21G    0.08802    0.02147   0.004252          8        416: 100% 29/29 [00:08<00:00,  3.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.04it/s]\n",
            "                   all        142        205      0.144     0.0488     0.0446    0.00971\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/99      5.21G    0.08567    0.02241   0.003451         18        416: 100% 29/29 [00:08<00:00,  3.40it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.67it/s]\n",
            "                   all        142        205      0.104      0.039     0.0314     0.0102\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/99      5.21G    0.08481    0.02223   0.002678         14        416: 100% 29/29 [00:08<00:00,  3.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.55it/s]\n",
            "                   all        142        205      0.157      0.229     0.0821     0.0185\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/99      5.21G    0.08241    0.02135   0.002167         17        416: 100% 29/29 [00:08<00:00,  3.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.32it/s]\n",
            "                   all        142        205      0.126     0.0976     0.0388      0.011\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/99      5.21G     0.0831    0.02201   0.001985         11        416: 100% 29/29 [00:08<00:00,  3.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.00it/s]\n",
            "                   all        142        205     0.0715      0.176     0.0476     0.0111\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/99      5.21G     0.0798    0.02153    0.00176         15        416: 100% 29/29 [00:08<00:00,  3.39it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.89it/s]\n",
            "                   all        142        205     0.0993        0.2     0.0378    0.00803\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/99      5.21G    0.07834     0.0215   0.001667         11        416: 100% 29/29 [00:08<00:00,  3.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.94it/s]\n",
            "                   all        142        205      0.166     0.0976     0.0597     0.0137\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/99      5.21G    0.07732     0.0216   0.001418         11        416: 100% 29/29 [00:08<00:00,  3.53it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.61it/s]\n",
            "                   all        142        205      0.236      0.239      0.142     0.0394\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/99      5.21G    0.07584    0.02092   0.001228          8        416: 100% 29/29 [00:08<00:00,  3.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:02<00:00,  2.42it/s]\n",
            "                   all        142        205     0.0499      0.166     0.0249    0.00581\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/99      5.21G    0.07544    0.02092   0.001423          9        416: 100% 29/29 [00:07<00:00,  3.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.63it/s]\n",
            "                   all        142        205      0.142     0.0829     0.0359    0.00805\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/99      5.21G    0.07186    0.02133   0.001043         16        416: 100% 29/29 [00:08<00:00,  3.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.07it/s]\n",
            "                   all        142        205      0.229      0.332      0.178      0.057\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/99      5.21G    0.07184     0.0212  0.0009782          7        416: 100% 29/29 [00:08<00:00,  3.54it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.29it/s]\n",
            "                   all        142        205      0.297      0.244      0.193     0.0579\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/99      5.21G    0.07157    0.02284   0.001092         19        416: 100% 29/29 [00:08<00:00,  3.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.57it/s]\n",
            "                   all        142        205      0.279      0.215      0.142     0.0415\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/99      5.21G    0.06889    0.02114  0.0009619         10        416: 100% 29/29 [00:08<00:00,  3.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.67it/s]\n",
            "                   all        142        205      0.328      0.268      0.223     0.0673\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/99      5.21G    0.06804    0.02147   0.001068         13        416: 100% 29/29 [00:08<00:00,  3.39it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.69it/s]\n",
            "                   all        142        205       0.44       0.22      0.193     0.0572\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/99      5.21G    0.06746    0.02202   0.001117         29        416: 100% 29/29 [00:08<00:00,  3.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.00it/s]\n",
            "                   all        142        205      0.425      0.283      0.245     0.0809\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/99      5.21G    0.06475    0.02155   0.001136         13        416: 100% 29/29 [00:08<00:00,  3.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.25it/s]\n",
            "                   all        142        205      0.488      0.354      0.313     0.0902\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/99      5.21G    0.06444    0.02131  0.0008691         10        416: 100% 29/29 [00:08<00:00,  3.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.22it/s]\n",
            "                   all        142        205       0.41       0.42      0.378      0.116\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/99      5.21G    0.06232    0.02073  0.0006971         16        416: 100% 29/29 [00:08<00:00,  3.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.96it/s]\n",
            "                   all        142        205      0.123      0.127       0.07     0.0243\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/99      5.21G    0.06261    0.02121   0.001298         13        416: 100% 29/29 [00:08<00:00,  3.57it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.81it/s]\n",
            "                   all        142        205      0.591      0.444      0.488      0.176\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/99      5.21G    0.06104    0.02052   0.001113         14        416: 100% 29/29 [00:08<00:00,  3.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.73it/s]\n",
            "                   all        142        205      0.474      0.234      0.224     0.0634\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/99      5.21G     0.0616    0.02117  0.0006914         10        416: 100% 29/29 [00:08<00:00,  3.62it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.01it/s]\n",
            "                   all        142        205      0.449       0.19      0.233      0.083\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/99      5.21G    0.06005     0.0206   0.001066         13        416: 100% 29/29 [00:08<00:00,  3.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.34it/s]\n",
            "                   all        142        205      0.057      0.346     0.0357     0.0109\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/99      5.21G    0.05889    0.01972  0.0007324          9        416: 100% 29/29 [00:08<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.36it/s]\n",
            "                   all        142        205      0.677      0.481      0.528      0.202\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/99      5.21G    0.05848    0.02033   0.001031         11        416: 100% 29/29 [00:08<00:00,  3.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.29it/s]\n",
            "                   all        142        205      0.474      0.378      0.338     0.0921\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/99      5.21G     0.0591     0.0203  0.0006194         11        416: 100% 29/29 [00:08<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.17it/s]\n",
            "                   all        142        205      0.464      0.161      0.147     0.0509\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/99      5.21G    0.05744    0.02004  0.0007181          5        416: 100% 29/29 [00:08<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.87it/s]\n",
            "                   all        142        205      0.522      0.263      0.232     0.0638\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/99      5.21G     0.0577    0.02041  0.0007524         12        416: 100% 29/29 [00:08<00:00,  3.62it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.80it/s]\n",
            "                   all        142        205      0.683      0.541      0.549      0.224\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/99      5.21G    0.05666    0.02012  0.0009274         14        416: 100% 29/29 [00:08<00:00,  3.62it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.85it/s]\n",
            "                   all        142        205      0.641      0.512      0.488      0.168\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/99      5.21G    0.05618    0.02037   0.001061         16        416: 100% 29/29 [00:08<00:00,  3.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.32it/s]\n",
            "                   all        142        205      0.653      0.302      0.353      0.137\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      40/99      5.21G    0.05706    0.02061  0.0007486          9        416: 100% 29/29 [00:08<00:00,  3.51it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.22it/s]\n",
            "                   all        142        205      0.529      0.283      0.296        0.1\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      41/99      5.21G    0.05762    0.01997  0.0008115         13        416: 100% 29/29 [00:08<00:00,  3.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.14it/s]\n",
            "                   all        142        205      0.717      0.429      0.457      0.159\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      42/99      5.21G    0.05514    0.02011  0.0007126         16        416: 100% 29/29 [00:08<00:00,  3.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.23it/s]\n",
            "                   all        142        205      0.696      0.379      0.411      0.144\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      43/99      5.21G    0.05507    0.02055  0.0007001         24        416: 100% 29/29 [00:08<00:00,  3.49it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.76it/s]\n",
            "                   all        142        205      0.617      0.228      0.251     0.0797\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      44/99      5.21G    0.05152     0.0201   0.000519         10        416: 100% 29/29 [00:07<00:00,  3.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.78it/s]\n",
            "                   all        142        205      0.461      0.229      0.201     0.0739\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      45/99      5.21G    0.05325    0.01953  0.0006083         10        416: 100% 29/29 [00:08<00:00,  3.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.26it/s]\n",
            "                   all        142        205      0.251      0.151     0.0961     0.0337\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      46/99      5.21G    0.05248    0.01883   0.000403          5        416: 100% 29/29 [00:08<00:00,  3.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.38it/s]\n",
            "                   all        142        205      0.419      0.376      0.302      0.118\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      47/99      5.21G    0.05368    0.02025  0.0007778         14        416: 100% 29/29 [00:08<00:00,  3.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.38it/s]\n",
            "                   all        142        205      0.671      0.467      0.545       0.23\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      48/99      5.21G    0.05069    0.01986  0.0006542         12        416: 100% 29/29 [00:08<00:00,  3.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.30it/s]\n",
            "                   all        142        205      0.679      0.517      0.521      0.214\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      49/99      5.21G    0.05121    0.01955   0.000494         15        416: 100% 29/29 [00:08<00:00,  3.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.03it/s]\n",
            "                   all        142        205      0.672       0.42      0.406      0.136\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      50/99      5.21G    0.05198     0.0197   0.000603         12        416: 100% 29/29 [00:08<00:00,  3.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.82it/s]\n",
            "                   all        142        205      0.733      0.361      0.411      0.143\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      51/99      5.21G    0.05044    0.01948  0.0005325         13        416: 100% 29/29 [00:08<00:00,  3.62it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.29it/s]\n",
            "                   all        142        205      0.744      0.541      0.601      0.235\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      52/99      5.21G    0.05076    0.01912   0.001001         16        416: 100% 29/29 [00:08<00:00,  3.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.37it/s]\n",
            "                   all        142        205      0.663      0.395      0.392      0.137\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      53/99      5.21G    0.04886    0.01885  0.0003847         12        416: 100% 29/29 [00:08<00:00,  3.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.34it/s]\n",
            "                   all        142        205      0.764      0.649      0.702      0.314\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      54/99      5.21G    0.04943    0.01856  0.0009514          9        416: 100% 29/29 [00:08<00:00,  3.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.40it/s]\n",
            "                   all        142        205      0.769       0.47      0.518      0.208\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      55/99      5.21G    0.04958    0.01919  0.0003405          9        416: 100% 29/29 [00:08<00:00,  3.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.22it/s]\n",
            "                   all        142        205      0.647      0.268      0.277     0.0823\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      56/99      5.21G    0.04936    0.01874  0.0004351         12        416: 100% 29/29 [00:08<00:00,  3.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.13it/s]\n",
            "                   all        142        205      0.619       0.39      0.401      0.133\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      57/99      5.21G    0.04858    0.01828  0.0003877         14        416: 100% 29/29 [00:07<00:00,  3.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.81it/s]\n",
            "                   all        142        205      0.764      0.584      0.673      0.279\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      58/99      5.21G    0.04791     0.0188  0.0007193         11        416: 100% 29/29 [00:08<00:00,  3.62it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.35it/s]\n",
            "                   all        142        205      0.724      0.666      0.726      0.316\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      59/99      5.21G    0.04847    0.01816   0.000589         12        416: 100% 29/29 [00:08<00:00,  3.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.24it/s]\n",
            "                   all        142        205      0.367      0.322      0.283      0.107\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      60/99      5.21G    0.04785    0.01844  0.0004433         12        416: 100% 29/29 [00:08<00:00,  3.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.38it/s]\n",
            "                   all        142        205      0.833      0.634      0.706      0.331\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      61/99      5.21G    0.04828    0.01948  0.0006531          9        416: 100% 29/29 [00:08<00:00,  3.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.33it/s]\n",
            "                   all        142        205      0.777      0.659      0.711      0.339\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      62/99      5.21G    0.04867    0.01868  0.0004393         16        416: 100% 29/29 [00:08<00:00,  3.38it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.34it/s]\n",
            "                   all        142        205      0.583      0.356        0.4      0.171\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      63/99      5.21G    0.04601    0.01926  0.0009029         17        416: 100% 29/29 [00:08<00:00,  3.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.32it/s]\n",
            "                   all        142        205      0.734      0.484      0.509      0.213\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      64/99      5.21G    0.04607    0.01776  0.0006302          6        416: 100% 29/29 [00:08<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.15it/s]\n",
            "                   all        142        205      0.662      0.561      0.554      0.231\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      65/99      5.21G    0.04704     0.0187  0.0007879         17        416: 100% 29/29 [00:07<00:00,  3.64it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.83it/s]\n",
            "                   all        142        205       0.61       0.39      0.383      0.145\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      66/99      5.21G    0.04555    0.01763  0.0004078         11        416: 100% 29/29 [00:08<00:00,  3.62it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.33it/s]\n",
            "                   all        142        205      0.768      0.678      0.701      0.323\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      67/99      5.21G    0.04637    0.01717  0.0007134          5        416: 100% 29/29 [00:08<00:00,  3.51it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.35it/s]\n",
            "                   all        142        205      0.798      0.551      0.632      0.288\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      68/99      5.21G    0.04659    0.01894  0.0004801         14        416: 100% 29/29 [00:08<00:00,  3.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.37it/s]\n",
            "                   all        142        205      0.713      0.439      0.431      0.175\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      69/99      5.21G    0.04637    0.01783  0.0002625         17        416: 100% 29/29 [00:08<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.36it/s]\n",
            "                   all        142        205       0.85      0.665      0.751      0.364\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      70/99      5.21G    0.04482    0.01696  0.0007423         12        416: 100% 29/29 [00:08<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.32it/s]\n",
            "                   all        142        205      0.789      0.522      0.618      0.281\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      71/99      5.21G     0.0456    0.01792  0.0005811          8        416: 100% 29/29 [00:08<00:00,  3.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.80it/s]\n",
            "                   all        142        205      0.882      0.657      0.744      0.366\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      72/99      5.21G    0.04373    0.01635  0.0003408          6        416: 100% 29/29 [00:08<00:00,  3.54it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.82it/s]\n",
            "                   all        142        205      0.721      0.507      0.527      0.216\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      73/99      5.21G     0.0445    0.01707  0.0003371          8        416: 100% 29/29 [00:08<00:00,  3.62it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.06it/s]\n",
            "                   all        142        205      0.769      0.556      0.651      0.292\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      74/99      5.21G     0.0447    0.01718  0.0002671         11        416: 100% 29/29 [00:08<00:00,  3.57it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.41it/s]\n",
            "                   all        142        205      0.823      0.712      0.775      0.375\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      75/99      5.21G    0.04397    0.01833  0.0002531         20        416: 100% 29/29 [00:08<00:00,  3.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.43it/s]\n",
            "                   all        142        205      0.744      0.493      0.471      0.184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      76/99      5.21G    0.04487    0.01732  0.0004544          6        416: 100% 29/29 [00:08<00:00,  3.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.31it/s]\n",
            "                   all        142        205      0.797      0.654      0.688      0.334\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      77/99      5.21G    0.04381    0.01695  0.0003457         10        416: 100% 29/29 [00:08<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.41it/s]\n",
            "                   all        142        205      0.832      0.707       0.78      0.386\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      78/99      5.21G    0.04416    0.01663  0.0002102          7        416: 100% 29/29 [00:08<00:00,  3.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.33it/s]\n",
            "                   all        142        205      0.772      0.649      0.696       0.33\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      79/99      5.21G    0.04261    0.01663  0.0001874         10        416: 100% 29/29 [00:08<00:00,  3.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.85it/s]\n",
            "                   all        142        205      0.746      0.605      0.618      0.275\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      80/99      5.21G    0.04228    0.01728  0.0005224         13        416: 100% 29/29 [00:07<00:00,  3.64it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.92it/s]\n",
            "                   all        142        205      0.774       0.58      0.622      0.267\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      81/99      5.21G    0.04167    0.01696  0.0004899          7        416: 100% 29/29 [00:08<00:00,  3.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.32it/s]\n",
            "                   all        142        205      0.802      0.751      0.771      0.393\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      82/99      5.21G    0.04336    0.01601  0.0006575          8        416: 100% 29/29 [00:08<00:00,  3.51it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.39it/s]\n",
            "                   all        142        205      0.699      0.453      0.475      0.202\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      83/99      5.21G    0.04129    0.01696  0.0005642         14        416: 100% 29/29 [00:08<00:00,  3.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.32it/s]\n",
            "                   all        142        205      0.866      0.693      0.754      0.379\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      84/99      5.21G    0.04176    0.01672  0.0006315          7        416: 100% 29/29 [00:08<00:00,  3.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.38it/s]\n",
            "                   all        142        205      0.863      0.677      0.766      0.381\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      85/99      5.21G    0.04133    0.01652  0.0002141          8        416: 100% 29/29 [00:08<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.99it/s]\n",
            "                   all        142        205      0.849      0.649      0.722      0.356\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      86/99      5.21G    0.04081    0.01688   0.000542         12        416: 100% 29/29 [00:08<00:00,  3.62it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.69it/s]\n",
            "                   all        142        205      0.853      0.688      0.757      0.379\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      87/99      5.21G    0.04065     0.0175  0.0004524          8        416: 100% 29/29 [00:08<00:00,  3.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.40it/s]\n",
            "                   all        142        205      0.772      0.562      0.586      0.253\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      88/99      5.21G    0.04081    0.01716  0.0002446         16        416: 100% 29/29 [00:08<00:00,  3.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.38it/s]\n",
            "                   all        142        205      0.879      0.604      0.679      0.322\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      89/99      5.21G    0.04035      0.017  0.0002893         10        416: 100% 29/29 [00:08<00:00,  3.46it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.32it/s]\n",
            "                   all        142        205      0.871      0.723      0.781      0.398\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      90/99      5.21G    0.04054    0.01601  0.0002487         13        416: 100% 29/29 [00:08<00:00,  3.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.36it/s]\n",
            "                   all        142        205      0.883        0.7       0.78      0.399\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      91/99      5.21G    0.04094    0.01611   0.001261          7        416: 100% 29/29 [00:08<00:00,  3.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.38it/s]\n",
            "                   all        142        205       0.88      0.698      0.774      0.382\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      92/99      5.21G    0.03969    0.01689     0.0003          7        416: 100% 29/29 [00:08<00:00,  3.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.97it/s]\n",
            "                   all        142        205      0.796      0.685      0.697      0.334\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      93/99      5.21G    0.04075    0.01664  0.0002034         18        416: 100% 29/29 [00:07<00:00,  3.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.84it/s]\n",
            "                   all        142        205      0.796      0.751      0.777      0.391\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      94/99      5.21G    0.04024    0.01653  0.0009738         13        416: 100% 29/29 [00:07<00:00,  3.65it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.33it/s]\n",
            "                   all        142        205      0.871      0.722       0.78        0.4\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      95/99      5.21G    0.03994    0.01652  0.0009962         10        416: 100% 29/29 [00:08<00:00,  3.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.39it/s]\n",
            "                   all        142        205      0.866      0.737      0.779      0.396\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      96/99      5.21G    0.03848    0.01688  0.0003268         25        416: 100% 29/29 [00:08<00:00,  3.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.38it/s]\n",
            "                   all        142        205      0.882      0.741      0.796      0.406\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      97/99      5.21G    0.03898    0.01597  0.0005308          7        416: 100% 29/29 [00:08<00:00,  3.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.37it/s]\n",
            "                   all        142        205       0.86      0.741      0.786       0.41\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      98/99      5.21G    0.03944    0.01649   0.000317         16        416: 100% 29/29 [00:08<00:00,  3.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  2.73it/s]\n",
            "                   all        142        205      0.856      0.727       0.78      0.407\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      99/99      5.21G    0.03906    0.01649  0.0001923         22        416: 100% 29/29 [00:08<00:00,  3.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:01<00:00,  3.04it/s]\n",
            "                   all        142        205      0.854      0.722       0.77      0.394\n",
            "\n",
            "100 epochs completed in 0.333 hours.\n",
            "Optimizer stripped from runs/train/yolov5s_results/weights/last.pt, 92.7MB\n",
            "Optimizer stripped from runs/train/yolov5s_results/weights/best.pt, 92.7MB\n",
            "\n",
            "Validating runs/train/yolov5s_results/weights/best.pt...\n",
            "Fusing layers... \n",
            "YOLOv5l summary: 267 layers, 46113663 parameters, 0 gradients, 107.7 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 5/5 [00:04<00:00,  1.24it/s]\n",
            "                   all        142        205       0.86      0.741      0.787      0.409\n",
            "               tenedor        142        205       0.86      0.741      0.787      0.409\n",
            "Results saved to \u001b[1mruns/train/yolov5s_results\u001b[0m\n",
            "CPU times: user 11.8 s, sys: 1.44 s, total: 13.3 s\n",
            "Wall time: 20min 38s\n"
          ]
        }
      ],
      "source": [
        "# train yolov5s on custom data for 100 epochs\n",
        "# time its performance\n",
        "%%time\n",
        "%cd /content/yolov5/\n",
        "!python train.py --img 416 --batch 16 --epochs 100 --data {dataset.location}/data.yaml  --cfg /content/yolov5/models/yolov5l.yaml  --weights ''  --name yolov5s_results  --cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJVs_4zEeVbF"
      },
      "source": [
        "# Evaluate Custom YOLOv5 Detector Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KN5ghjE6ZWh"
      },
      "source": [
        "Training losses and performance metrics are saved to Tensorboard and also to a logfile defined above with the **--name** flag when we train. In our case, we named this `yolov5s_results`. (If given no name, it defaults to `results.txt`.) The results file is plotted as a png after training completes.\n",
        "\n",
        "Note from Glenn: Partially completed `results.txt` files can be plotted with `from utils.utils import plot_results; plot_results()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "id": "bOy5KI2ncnWd",
        "outputId": "273e437a-7eda-4a0e-dd79-c09c7c6aec27",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Start tensorboard\n",
        "# Launch after you have started training\n",
        "# logs save in the folder \"runs\"\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "C60XAsyv6OPe",
        "outputId": "8cc02851-055c-49f3-c8e4-9304b93e0e5e",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-d7ea088d00dd>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# we can also output some older school graphs if the tensor board isn't working for whatever reason...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplots\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_results\u001b[0m  \u001b[0;31m# plot results.txt as results.png\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/yolov5/runs/train/yolov5s_results/results.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# view results.png\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils.plots'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# we can also output some older school graphs if the tensor board isn't working for whatever reason...\n",
        "from utils.plots import plot_results  # plot results.txt as results.png\n",
        "Image(filename='/content/yolov5/runs/train/yolov5s_results/results.png', width=1000)  # view results.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLI1JmHU7B0l"
      },
      "source": [
        "### Curious? Visualize Our Training Data with Labels\n",
        "\n",
        "After training starts, view `train*.jpg` images to see training images, labels and augmentation effects.\n",
        "\n",
        "Note a mosaic dataloader is used for training (shown below), a new dataloading concept developed by Glenn Jocher and first featured in [YOLOv4](https://arxiv.org/abs/2004.10934)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "PF9MLHDb7tB6",
        "outputId": "4a9cea5e-8878-4e01-a04b-1591e0aa750d",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GROUND TRUTH TRAINING DATA:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-7c5574a13794>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# first, display our ground truth data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GROUND TRUTH TRAINING DATA:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/yolov5/runs/train/yolov5s_results/test_batch0_labels.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m900\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m   1229\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretina\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m         super(Image, self).__init__(data=data, url=url, filename=filename, \n\u001b[0m\u001b[1;32m   1232\u001b[0m                 metadata=metadata)\n\u001b[1;32m   1233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1261\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1264\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/yolov5/runs/train/yolov5s_results/test_batch0_labels.jpg'"
          ]
        }
      ],
      "source": [
        "# first, display our ground truth data\n",
        "print(\"GROUND TRUTH TRAINING DATA:\")\n",
        "Image(filename='/content/yolov5/runs/train/yolov5s_results/test_batch0_labels.jpg', width=900)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6_8TNctFprOo",
        "outputId": "5e020f01-2cf2-4c0a-b05e-ee85fa6c5735",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "id": "t_DLOnZTp4J6",
        "outputId": "e1fd3ae5-632d-4a79-f709-2245b5865531",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cp -r /content/agent-yolov5 /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "Qr20YrsgpwGd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "W40tI99_7BcH",
        "outputId": "4961f659-7aa6-4496-fa6c-9d5c6927febe",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GROUND TRUTH AUGMENTED TRAINING DATA:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-6e113e1f0c3d>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# print out an augmented training example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GROUND TRUTH AUGMENTED TRAINING DATA:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/yolov5/runs/train/yolov5s_results/train_batch0.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m900\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m   1229\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretina\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m         super(Image, self).__init__(data=data, url=url, filename=filename, \n\u001b[0m\u001b[1;32m   1232\u001b[0m                 metadata=metadata)\n\u001b[1;32m   1233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1261\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1264\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/yolov5/runs/train/yolov5s_results/train_batch0.jpg'"
          ]
        }
      ],
      "source": [
        "# print out an augmented training example\n",
        "print(\"GROUND TRUTH AUGMENTED TRAINING DATA:\")\n",
        "Image(filename='/content/yolov5/runs/train/yolov5s_results/train_batch0.jpg', width=900)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3qM6T0W53gh"
      },
      "source": [
        "#Run Inference  With Trained Weights\n",
        "Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIEwt5YLeQ7P",
        "outputId": "d042529c-2d05-49e1-f53c-a8aac20eaab7",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mtrain\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "# trained weights are saved by default in our weights folder\n",
        "%ls runs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SyOWS80qR32",
        "outputId": "53ece1df-82ed-4db9-eb7c-7de938ee493c",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best.pt  last.pt\n"
          ]
        }
      ],
      "source": [
        "%ls runs/train/yolov5s_results/weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nmZZnWOgJ2S",
        "outputId": "9d56f834-e5f3-43dc-b935-a4c5827e2c36",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/yolov5\n",
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.4, device='', exist_ok=False, img_size=416, iou_thres=0.45, name='exp', project='runs/detect', save_conf=False, save_txt=False, source='../test/images', update=False, view_img=False, weights=['runs/train/yolov5s_results/weights/best.pt'])\n",
            "Using torch 1.7.1+cu101 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 232 layers, 7251912 parameters, 0 gradients\n",
            "image 1/36 /content/test/images/BloodImage_00038_jpg.rf.ffa23e4b5b55b523367f332af726eae8.jpg: 416x416 Done. (0.204s)\n",
            "image 2/36 /content/test/images/BloodImage_00044_jpg.rf.e7760375eba4bc20c5746367e2311e18.jpg: 416x416 Done. (0.171s)\n",
            "image 3/36 /content/test/images/BloodImage_00062_jpg.rf.1be1ca0ecdf783798fc10346baaa203e.jpg: 416x416 Done. (0.173s)\n",
            "image 4/36 /content/test/images/BloodImage_00090_jpg.rf.cdbf8f6ed3b93fa902a0bc991132cb40.jpg: 416x416 Done. (0.163s)\n",
            "image 5/36 /content/test/images/BloodImage_00099_jpg.rf.e3c42cd68359527494a53843479dff5c.jpg: 416x416 Done. (0.169s)\n",
            "image 6/36 /content/test/images/BloodImage_00112_jpg.rf.978cec39235980055c2ad7ff8b6f1912.jpg: 416x416 Done. (0.172s)\n",
            "image 7/36 /content/test/images/BloodImage_00113_jpg.rf.a17463f1ddc2e7729f935f8a74bc86a4.jpg: 416x416 Done. (0.174s)\n",
            "image 8/36 /content/test/images/BloodImage_00120_jpg.rf.6725d54bf5615683448eb1de4c7577ee.jpg: 416x416 Done. (0.168s)\n",
            "image 9/36 /content/test/images/BloodImage_00133_jpg.rf.39ee4e4a097a7b40defa56aea6533caf.jpg: 416x416 Done. (0.164s)\n",
            "image 10/36 /content/test/images/BloodImage_00134_jpg.rf.0d9da503b62e0034a2819a39cce7e7d9.jpg: 416x416 Done. (0.166s)\n",
            "image 11/36 /content/test/images/BloodImage_00154_jpg.rf.e5b45569e9cbede1ed36f82f14566c29.jpg: 416x416 Done. (0.163s)\n",
            "image 12/36 /content/test/images/BloodImage_00160_jpg.rf.894e8c8c7179ec9958a4d6c7b6b45616.jpg: 416x416 Done. (0.173s)\n",
            "image 13/36 /content/test/images/BloodImage_00190_jpg.rf.3e0bf272a5f8ea902775e4cbc56c538c.jpg: 416x416 Done. (0.164s)\n",
            "image 14/36 /content/test/images/BloodImage_00191_jpg.rf.313648dd345edbdd005886613a01fe5d.jpg: 416x416 Done. (0.167s)\n",
            "image 15/36 /content/test/images/BloodImage_00204_jpg.rf.04ba9998769a12d374e6c4b284e6a4a2.jpg: 416x416 Done. (0.170s)\n",
            "image 16/36 /content/test/images/BloodImage_00227_jpg.rf.d1790b0cdc042312d1e0af86a5c13519.jpg: 416x416 Done. (0.167s)\n",
            "image 17/36 /content/test/images/BloodImage_00235_jpg.rf.283fff79a1188b82f5a544d381909c2d.jpg: 416x416 Done. (0.165s)\n",
            "image 18/36 /content/test/images/BloodImage_00241_jpg.rf.757020b43fe3414a0f66770f54da283f.jpg: 416x416 Done. (0.167s)\n",
            "image 19/36 /content/test/images/BloodImage_00254_jpg.rf.e95bc889425924cc7a35a7b0cea4d470.jpg: 416x416 Done. (0.163s)\n",
            "image 20/36 /content/test/images/BloodImage_00265_jpg.rf.7d102d5f38caddb90a465912fb7bdc5c.jpg: 416x416 Done. (0.167s)\n",
            "image 21/36 /content/test/images/BloodImage_00266_jpg.rf.2521623f1047a9502b2705a626ad6655.jpg: 416x416 Done. (0.165s)\n",
            "image 22/36 /content/test/images/BloodImage_00275_jpg.rf.585f5abcf10f926c74ac2e2340bbdf44.jpg: 416x416 Done. (0.164s)\n",
            "image 23/36 /content/test/images/BloodImage_00278_jpg.rf.cfe491c301184766df6aa73fa48a7f33.jpg: 416x416 Done. (0.165s)\n",
            "image 24/36 /content/test/images/BloodImage_00284_jpg.rf.63402cee4454cb6d7655b83cacc29817.jpg: 416x416 Done. (0.189s)\n",
            "image 25/36 /content/test/images/BloodImage_00289_jpg.rf.72f51d668e5ebc31700b1a10e8f7dec8.jpg: 416x416 Done. (0.164s)\n",
            "image 26/36 /content/test/images/BloodImage_00301_jpg.rf.885ee9fbea0573ba35b9561a5d1d0437.jpg: 416x416 Done. (0.162s)\n",
            "image 27/36 /content/test/images/BloodImage_00302_jpg.rf.911302bb5caaf9467e101afeece651e1.jpg: 416x416 Done. (0.167s)\n",
            "image 28/36 /content/test/images/BloodImage_00325_jpg.rf.c8ab9fc71ad718a95901a00cc18c27e6.jpg: 416x416 Done. (0.162s)\n",
            "image 29/36 /content/test/images/BloodImage_00334_jpg.rf.8b2c2a9c5a39e78eb74aa26c82967069.jpg: 416x416 Done. (0.164s)\n",
            "image 30/36 /content/test/images/BloodImage_00336_jpg.rf.8d3e710e8696c10bcbb101dc8a553ca0.jpg: 416x416 Done. (0.168s)\n",
            "image 31/36 /content/test/images/BloodImage_00337_jpg.rf.b6cb228440b9158cafec01a0351e3aad.jpg: 416x416 Done. (0.167s)\n",
            "image 32/36 /content/test/images/BloodImage_00350_jpg.rf.e2c472c90de4ce51fe4f21b093db6ece.jpg: 416x416 Done. (0.165s)\n",
            "image 33/36 /content/test/images/BloodImage_00359_jpg.rf.03331bc3903822adbe982fe9e7cd061b.jpg: 416x416 Done. (0.166s)\n",
            "image 34/36 /content/test/images/BloodImage_00369_jpg.rf.c3818de705d661536ed7e4ce49040020.jpg: 416x416 Done. (0.162s)\n",
            "image 35/36 /content/test/images/BloodImage_00385_jpg.rf.865551dd16b189945cbba0fe51baa151.jpg: 416x416 Done. (0.170s)\n",
            "image 36/36 /content/test/images/BloodImage_00386_jpg.rf.c708422b2d9c642f200a853e70012850.jpg: 416x416 Done. (0.169s)\n",
            "Results saved to runs/detect/exp2\n",
            "Done. (6.319s)\n"
          ]
        }
      ],
      "source": [
        "# when we ran this, we saw .007 second inference time. That is 140 FPS on a TESLA P100!\n",
        "# use the best weights!\n",
        "%cd /content/yolov5/\n",
        "!python detect.py --weights runs/train/yolov5s_results/weights/best.pt --img 416 --conf 0.4 --source ../test/images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odKEqYtTgbRc",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#display inference on ALL test images\n",
        "#this looks much better with longer training above\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for imageName in glob.glob('/content/yolov5/runs/detect/exp/*.jpg'): #assuming JPG\n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uPq9mVgiBql"
      },
      "source": [
        "# Deploy Model Weights to Roboflow\n",
        "\n",
        "Now that you have trained your custom detector, you can upload it to Roboflow to deploy you model to a Hosted API and edge containers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "p7wPg_6JibJi"
      },
      "outputs": [],
      "source": [
        "project.version(dataset.version).deploy(model_type=\"yolov5\", model_path=f\"/content/yolov5/runs/train/yolov5s_results/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "9uvDUZphibJi"
      },
      "outputs": [],
      "source": [
        "#While your deployment is processing, checkout the deployment docs to take your model to most destinations https://docs.roboflow.com/inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "PBT-AUmXibJi"
      },
      "outputs": [],
      "source": [
        "#Run inference on your model on a persistant, auto-scaling, cloud API\n",
        "\n",
        "#load model\n",
        "model = project.version(dataset.version).model\n",
        "\n",
        "#choose random test set image\n",
        "import os, random\n",
        "test_set_loc = dataset.location + \"/test/images/\"\n",
        "random_test_image = random.choice(os.listdir(test_set_loc))\n",
        "print(\"running inference on \" + random_test_image)\n",
        "\n",
        "pred = model.predict(test_set_loc + random_test_image, confidence=40, overlap=30).json()\n",
        "pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVpCFeU-K4gb"
      },
      "source": [
        "## Congrats!\n",
        "\n",
        "Hope you enjoyed this!\n",
        "\n",
        "--Team [Roboflow](https://roboflow.ai)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}