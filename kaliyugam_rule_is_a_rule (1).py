# -*- coding: utf-8 -*-
"""KALIYUGAM RULE IS A RULE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pS4Eb1WPEJ7ob3SsNcjecG3jvuHEiah1
"""

!pip install pydub

from pydub import AudioSegment

# Load the MP3 audio file using pydub
audio = AudioSegment.from_mp3('/content/audion.mp3')

# Export the audio to a WAV file
output_wav_filename = '/content/output.wav'
audio.export(output_wav_filename, format="wav")

print("MP3 to WAV conversion complete.")

import numpy as np
import scipy.signal as signal
import scipy.io.wavfile as wavfile
import matplotlib.pyplot as plt

# Load an example audio signal (replace with your own audio file)
sample_rate, audio_signal = wavfile.read('/content/output.wav')

# Define the frequency to filter out (987 Hz)
filter_frequency = 987.7666025122486879070

# Design a Butterworth bandstop filter
nyquist = 0.5 * sample_rate
low_cutoff = filter_frequency - 10  # Adjust as needed
high_cutoff = filter_frequency + 10  # Adjust as needed
order = 4  # Filter order
b, a = signal.butter(order, [low_cutoff / nyquist, high_cutoff / nyquist], btype='bandstop')

# Apply the filter to the audio signal
filtered_audio = signal.lfilter(b, a, audio_signal)

# Plot the original and filtered audio signals
plt.figure(figsize=(10, 6))
plt.plot(audio_signal, label='Original Audio')
plt.plot(filtered_audio, label='Filtered Audio')
plt.xlabel('Sample')
plt.ylabel('Amplitude')
plt.title('Original vs Filtered Audio')
plt.legend()
plt.show()

# Save the filtered audio as a new WAV file
filtered_output_wav = 'filtered_audio.wav'
wavfile.write(filtered_output_wav, sample_rate, filtered_audio.astype(np.int16))

import numpy as np
import scipy.signal as signal
import scipy.io.wavfile as wavfile
import matplotlib.pyplot as plt

# Load an example audio signal (replace with your own audio file)
sample_rate, audio_signal = wavfile.read('/content/output.wav')

# Define the frequency to filter out (987.7666025122486879070 Hz)
filter_frequency = 987.7666025122486879070

# Design a Butterworth notch filter
nyquist = 0.5 * sample_rate
low_cutoff = filter_frequency - 10  # Adjust as needed
high_cutoff = filter_frequency + 10  # Adjust as needed
order = 4  # Filter order
b, a = signal.iirnotch(filter_frequency / nyquist, Q=10)

# Apply the filter to the audio signal
filtered_audio = signal.lfilter(b, a, audio_signal)

# Plot the original and filtered audio signals
plt.figure(figsize=(10, 6))
plt.plot(audio_signal, label='Original Audio')
plt.plot(filtered_audio, label='Filtered Audio')
plt.xlabel('Sample')
plt.ylabel('Amplitude')
plt.title('Original vs Filtered Audio')
plt.legend()
plt.show()

# Save the filtered audio as a new WAV file
filtered_output_wav = 'filtered_audio.wav'
wavfile.write(filtered_output_wav, sample_rate, filtered_audio.astype(np.int16))

import numpy as np
import scipy.signal as signal
import scipy.io.wavfile as wavfile
import matplotlib.pyplot as plt

# Load an example audio signal (replace with your own audio file)
sample_rate, audio_signal = wavfile.read('/content/output.wav')

# Define the frequency to filter out (987.7666025122486879070 Hz)
filter_frequency = 987.7666025122486879070

# Design a higher order Butterworth notch filter
nyquist = 0.5 * sample_rate
notch_width = 2.0  # Adjust as needed for desired attenuation
Q = filter_frequency / notch_width
b, a = signal.iirnotch(w0=filter_frequency / nyquist, Q=Q)

# Apply the filter to the audio signal
filtered_audio = signal.lfilter(b, a, audio_signal)

# Plot the original and filtered audio signals
plt.figure(figsize=(10, 6))
plt.plot(audio_signal, label='Original Audio')
plt.plot(filtered_audio, label='Filtered Audio')
plt.xlabel('Sample')
plt.ylabel('Amplitude')
plt.title('Original vs Filtered Audio')
plt.legend()
plt.show()

# Save the filtered audio as a new WAV file
filtered_output_wav = 'filtered_audio.wav'
wavfile.write(filtered_output_wav, sample_rate, filtered_audio.astype(np.int16))

import numpy as np
import scipy.io.wavfile as wavfile
import matplotlib.pyplot as plt

# Load an example audio signal (replace with your own audio file)
sample_rate, audio_signal = wavfile.read('/content/output.wav')

# Define the frequency to remove (987.7666025122486879070 Hz)
filter_frequency = 987.7666025122486879070

# Calculate the time array and frequency bins
time_array = np.arange(len(audio_signal)) / sample_rate
frequency_bins = np.fft.fftfreq(len(audio_signal), d=1/sample_rate)

# Calculate the FFT of the audio signal
audio_spectrum = np.fft.fft(audio_signal)

# Find the index corresponding to the specified frequency
frequency_index = np.argmin(np.abs(frequency_bins - filter_frequency))

# Remove the frequency component by setting its magnitude to zero
audio_spectrum[frequency_index] = 0

# Perform the inverse FFT to obtain the filtered audio signal
filtered_audio = np.fft.ifft(audio_spectrum).real

# Plot the original and filtered audio signals
plt.figure(figsize=(10, 6))
plt.plot(time_array, audio_signal, label='Original Audio')
plt.plot(time_array, filtered_audio, label='Filtered Audio')
plt.xlabel('Time (s)')
plt.ylabel('Amplitude')
plt.title('Original vs Filtered Audio')
plt.legend()
plt.show()

# Save the filtered audio as a new WAV file
filtered_output_wav = 'filtered_audio.wav'
wavfile.write(filtered_output_wav, sample_rate, filtered_audio.astype(np.int16))

import numpy as np
import scipy.signal as signal
import scipy.io.wavfile as wavfile
import matplotlib.pyplot as plt

# Load an example audio signal (replace with your own audio file)
sample_rate, audio_signal = wavfile.read('/content/output.wav')

# Define the frequency to filter out (987.7666025122486879070 Hz)
filter_frequency = 987.7666025122486879070

# Design a higher order Butterworth notch filter
nyquist = 0.5 * sample_rate
notch_width = 0.001  # Adjust as needed for desired attenuation
Q = filter_frequency / notch_width
b, a = signal.iirnotch(w0=filter_frequency / nyquist, Q=Q)

# Apply the filter to the audio signal
filtered_audio = signal.lfilter(b, a, audio_signal)

# Plot the original and filtered audio signals
plt.figure(figsize=(10, 6))
plt.plot(audio_signal, label='Original Audio')
plt.plot(filtered_audio, label='Filtered Audio')
plt.xlabel('Sample')
plt.ylabel('Amplitude')
plt.title('Original vs Filtered Audio')
plt.legend()
plt.show()

# Save the filtered audio as a new WAV file
filtered_output_wav = 'filtered_audio.wav'
wavfile.write(filtered_output_wav, sample_rate, filtered_audio.astype(np.int16))

import numpy as np

# Define the key number for B5 in a 36-key piano (assuming A0 is the first key)
key_number = 36  # B5 is the 22nd key

# Calculate the frequency of B5 piano key with more decimal places
base_frequency = 27.5  # Frequency of A0 key
frequency_multiplier = 2 ** (key_number / 12)
b5_frequency = base_frequency * frequency_multiplier

print(f"The frequency of B5 piano key in a 36-key piano is: {b5_frequency:.1000f} Hz")

import numpy as np

# Define the key number for B5 in a 36-key piano (assuming A0 is the first key)
key_number = 23  # B5 is the 23rd key

# Calculate the frequency of B5 piano key
base_frequency = 27.5  # Frequency of A0 key
frequency_multiplier = 2 ** (key_number / 12)
b5_frequency = base_frequency * frequency_multiplier

print(f"The frequency of B5 piano key in a 36-key piano is: {b5_frequency:.1000f} Hz")

import numpy as np
import scipy.signal as signal
import scipy.io.wavfile as wavfile
import matplotlib.pyplot as plt

def apply_notch_filter(input_wav, output_wav, filter_frequency, sample_rate, notch_width=10, q_value=10):
    # Load the audio signal
    sample_rate, audio_signal = wavfile.read(input_wav)

    # Design a Butterworth notch filter
    nyquist = 0.5 * sample_rate
    low_cutoff = filter_frequency - notch_width
    high_cutoff = filter_frequency + notch_width
    b, a = signal.iirnotch(filter_frequency / nyquist, Q=q_value)

    # Apply the filter to the audio signal
    filtered_audio = signal.lfilter(b, a, audio_signal)

    # Save the filtered audio as a new WAV file
    wavfile.write(output_wav, sample_rate, filtered_audio.astype(np.int16))

    # Plot the original and filtered audio signals
    plt.figure(figsize=(10, 6))
    plt.plot(audio_signal, label='Original Audio')
    plt.plot(filtered_audio, label='Filtered Audio')
    plt.xlabel('Sample')
    plt.ylabel('Amplitude')
    plt.title('Original vs Filtered Audio')
    plt.legend()
    plt.show()

# Define file paths and parameters
input_wav_file = '/content/output.wav'
output_wav_file = 'filtered_audio.wav'
filter_frequency = 987.7666025122486879070
sample_rate = None  # To be determined from the input file

# Call the function to apply the notch filter
apply_notch_filter(input_wav_file, output_wav_file, filter_frequency, sample_rate)

import numpy as np
import scipy.signal as signal
import scipy.io.wavfile as wavfile
import matplotlib.pyplot as plt
import csv

def apply_notch_filter(input_wav, output_wav, filter_frequency, sample_rate, notch_width=10, q_value=10):
    # Load the audio signal
    sample_rate, audio_signal = wavfile.read(input_wav)

    # Design a Butterworth notch filter
    nyquist = 0.5 * sample_rate
    low_cutoff = filter_frequency - notch_width
    high_cutoff = filter_frequency + notch_width
    b, a = signal.iirnotch(filter_frequency / nyquist, Q=q_value)

    # Apply the filter to the audio signal
    filtered_audio = signal.lfilter(b, a, audio_signal)

    # Save the filtered audio as a new WAV file
    wavfile.write(output_wav, sample_rate, filtered_audio.astype(np.int16))

    # Export frequency and sample rate as a CSV file
    csv_output_file = 'filtered_frequency.csv'
    with open(csv_output_file, mode='w', newline='') as csvfile:
        csv_writer = csv.writer(csvfile)
        csv_writer.writerow(['Frequency (Hz)', 'Sample Rate'])
        csv_writer.writerow([filter_frequency, sample_rate])

    # Plot the original and filtered audio signals
    plt.figure(figsize=(10, 6))
    plt.plot(audio_signal, label='Original Audio')
    plt.plot(filtered_audio, label='Filtered Audio')
    plt.xlabel('Sample')
    plt.ylabel('Amplitude')
    plt.title('Original vs Filtered Audio')
    plt.legend()
    plt.show()

# Define file paths and parameters
input_wav_file = '/content/output.wav'
output_wav_file = 'filtered_audio.wav'
filter_frequency = 987.7666025122486879070
sample_rate = None  # To be determined from the input file

# Call the function to apply the notch filter
apply_notch_filter(input_wav_file, output_wav_file, filter_frequency, sample_rate)

import numpy as np
import scipy.signal as signal
import scipy.io.wavfile as wavfile
import matplotlib.pyplot as plt
import csv

def apply_notch_filter(input_wav, output_wav, csv_file, notch_width=10, q_value=10):
    # Load the audio signal
    sample_rate, audio_signal = wavfile.read(input_wav)

    # Read filtered frequency and sample rate from CSV
    with open(csv_file, mode='r') as csvfile:
        csv_reader = csv.reader(csvfile)
        next(csv_reader)  # Skip header
        for row in csv_reader:
            filter_frequency, sample_rate = float(row[0]), int(row[1])

    # Design a Butterworth notch filter
    nyquist = 0.5 * sample_rate
    low_cutoff = filter_frequency - notch_width
    high_cutoff = filter_frequency + notch_width
    b, a = signal.iirnotch(filter_frequency / nyquist, Q=q_value)

    # Apply the filter to the audio signal
    filtered_audio = signal.lfilter(b, a, audio_signal)

    # Save the filtered audio as a new WAV file
    wavfile.write(output_wav, sample_rate, filtered_audio.astype(np.int16))

    # Plot the original and filtered audio signals
    plt.figure(figsize=(10, 6))
    plt.plot(audio_signal, label='Original Audio')
    plt.plot(filtered_audio, label='Filtered Audio')
    plt.xlabel('Sample')
    plt.ylabel('Amplitude')
    plt.title('Original vs Filtered Audio')
    plt.legend()
    plt.show()

# Define file paths and parameters
input_wav_file = '/content/output.wav'
output_wav_file = 'filtered_audio.wav'
filtered_csv_file = 'filtered_frequency.csv'

# Call the function to apply the notch filter
apply_notch_filter(input_wav_file, output_wav_file, filtered_csv_file)

from pydub import AudioSegment

# Load the MP3 audio file using pydub
audio = AudioSegment.from_mp3('/content/audion.mp3')

# Export the audio to a WAV file
output_wav_filename = '/content/TEST.wav'
audio.export(output_wav_filename, format="wav")

print("MP3 to WAV conversion complete.")

import numpy as np
import scipy.signal as signal
import scipy.io.wavfile as wavfile
import matplotlib.pyplot as plt
import csv

def apply_notch_filter(input_wav, output_wav, filter_frequency, sample_rate, num_iterations=100, notch_width=10, q_value=10):
    # Load the audio signal
    sample_rate, audio_signal = wavfile.read(input_wav)

    # Design a Butterworth notch filter
    nyquist = 0.5 * sample_rate
    low_cutoff = filter_frequency - notch_width
    high_cutoff = filter_frequency + notch_width

    # Apply the notch filter iteratively
    filtered_audio = audio_signal
    for i in range(num_iterations):
        b, a = signal.iirnotch(filter_frequency / nyquist, Q=q_value)
        filtered_audio = signal.lfilter(b, a, filtered_audio)

    # Save the filtered audio as a new WAV file
    wavfile.write(output_wav, sample_rate, filtered_audio.astype(np.int16))

    # Plot the original and filtered audio signals
    plt.figure(figsize=(10, 6))
    plt.plot(audio_signal, label='Original Audio')
    plt.plot(filtered_audio, label='Filtered Audio')
    plt.xlabel('Sample')
    plt.ylabel('Amplitude')
    plt.title('Original vs Filtered Audio')
    plt.legend()
    plt.show()

# Define file paths and parameters
input_wav_file = '/content/AAoutput.wav'
output_wav_file = 'filtered_audio.wav'
filtered_csv_file = 'filtered_frequency.csv'

# Read filtered frequency and sample rate from CSV
with open(filtered_csv_file, mode='r') as csvfile:
    csv_reader = csv.reader(csvfile)
    next(csv_reader)  # Skip header
    for row in csv_reader:
        filter_frequency, sample_rate = float(row[0]), int(row[1])

# Call the function to apply the notch filter iteratively
apply_notch_filter(input_wav_file, output_wav_file, filter_frequency, sample_rate, num_iterations=10000)

import scipy.io.wavfile as wavfile
import csv

def export_audio_info(input_wav, output_csv):
    # Load the audio file
    sample_rate, audio_signal = wavfile.read(input_wav)

    # Determine the bit depth
    bit_depth = audio_signal.dtype.itemsize * 8

    # Write the audio information to the CSV file
    with open(output_csv, mode='w', newline='') as csvfile:
        csv_writer = csv.writer(csvfile)
        csv_writer.writerow(['SampleRate', 'BitDepth'])
        csv_writer.writerow([sample_rate, bit_depth])

# Define file paths
input_wav_file = '/content/output.wav'
output_csv_file = 'audio_info.csv'

# Call the function to export the audio information
export_audio_info(input_wav_file, output_csv_file)

import numpy as np
import scipy.signal as signal
import scipy.io.wavfile as wavfile
import csv

def export_dominant_frequencies(input_wav, output_csv):
    # Load the audio signal
    sample_rate, audio_signal = wavfile.read(input_wav)

    # Perform Fourier Transform to obtain frequency spectrum
    frequencies, amplitudes = signal.welch(audio_signal, fs=sample_rate)

    # Find the dominant frequency component
    dominant_index = np.argmax(amplitudes)
    dominant_frequency = frequencies[dominant_index]

    # Write the dominant frequency and sample rate to the CSV file
    with open(output_csv, mode='w', newline='') as csvfile:
        csv_writer = csv.writer(csvfile)
        csv_writer.writerow(['DominantFrequency', 'SampleRate'])
        csv_writer.writerow([dominant_frequency, sample_rate])

# Define file paths and parameters
input_wav_file = '/content/TEST.wav'
output_csv_file = 'dominant_frequency.csv'

# Call the function to export the dominant frequency and sample rate
export_dominant_frequencies(input_wav_file, output_csv_file)

import numpy as np
import scipy.signal as signal
import scipy.io.wavfile as wavfile
import csv
import librosa

def analyze_sound(input_wav, output_csv):
    # Load the audio signal
    audio_signal, sample_rate = librosa.load(input_wav, sr=None)

    # Perform Fourier Transform to obtain frequency spectrum
    frequencies, amplitudes = signal.welch(audio_signal, fs=sample_rate)

    # Find the dominant frequency component
    dominant_index = np.argmax(amplitudes)
    dominant_frequency = frequencies[dominant_index]

    # Extract more features using librosa (e.g., chroma, mfcc, etc.)
    chroma_features = librosa.feature.chroma_stft(y=audio_signal, sr=sample_rate)
    mfcc_features = librosa.feature.mfcc(y=audio_signal, sr=sample_rate)

    # Write the extracted features and sample rate to the CSV file
    with open(output_csv, mode='w', newline='') as csvfile:
        csv_writer = csv.writer(csvfile)
        csv_writer.writerow(['DominantFrequency', 'SampleRate'])
        csv_writer.writerow([dominant_frequency, sample_rate])

        csv_writer.writerow(['ChromaFeatures'])
        csv_writer.writerows(chroma_features.T)

        csv_writer.writerow(['MFCCFeatures'])
        csv_writer.writerows(mfcc_features.T)

# Define file paths and parameters
input_wav_file = '/content/output.wav'
output_csv_file = 'sound_analysis.csv'

# Call the function to analyze the sound and export features
analyze_sound(input_wav_file, output_csv_file)

import numpy as np
import scipy.signal as signal
import scipy.io.wavfile as wavfile
import csv

def export_dominant_frequencies(input_wav, output_csv):
    # Load the audio signal
    sample_rate, audio_signal = wavfile.read(input_wav)

    # Perform Fourier Transform to obtain frequency spectrum
    frequencies, amplitudes = signal.welch(audio_signal, fs=sample_rate)

    # Find peaks in the frequency spectrum
    peak_indices, _ = signal.find_peaks(amplitudes, height=0.5)  # Adjust height threshold as needed
    dominant_index = peak_indices[np.argmax(amplitudes[peak_indices])]
    dominant_frequency = frequencies[dominant_index]

    # Write the dominant frequency and sample rate to the CSV file
    with open(output_csv, mode='w', newline='') as csvfile:
        csv_writer = csv.writer(csvfile)
        csv_writer.writerow(['DominantFrequency', 'SampleRate'])
        csv_writer.writerow([dominant_frequency, sample_rate])

# Define file paths and parameters
input_wav_file = '/content/TEST.wav'
output_csv_file = 'domiSnant_frequency.csv'

# Call the function to export the dominant frequency and sample rate
export_dominant_frequencies(input_wav_file, output_csv_file)

import numpy as np
import scipy.signal as signal
import scipy.io.wavfile as wavfile
import csv

def export_dominant_frequencies(input_wav, output_csv, prominence_threshold=5.0, height_threshold=50.0):
    # Load the audio signal
    sample_rate, audio_signal = wavfile.read(input_wav)

    # Perform Fourier Transform to obtain frequency spectrum
    frequencies, amplitudes = signal.welch(audio_signal, fs=sample_rate)

    # Find peaks in the frequency spectrum using customized parameters
    peak_indices, _ = signal.find_peaks(amplitudes, prominence=prominence_threshold, height=height_threshold)

    if len(peak_indices) > 0:
        dominant_index = peak_indices[np.argmax(amplitudes[peak_indices])]
        dominant_frequency = frequencies[dominant_index]
    else:
        dominant_frequency = None

    # Write the dominant frequency and sample rate to the CSV file
    with open(output_csv, mode='w', newline='') as csvfile:
        csv_writer = csv.writer(csvfile)
        csv_writer.writerow(['DominantFrequency', 'SampleRate'])
        if dominant_frequency is not None:
            csv_writer.writerow([dominant_frequency, sample_rate])
        else:
            csv_writer.writerow(['Not Found', sample_rate])

# Define file paths and parameters
input_wav_file = '/content/TEST.wav'
output_csv_file = 'dominant_frequency.csv'

# Call the function to export the dominant frequency and sample rate
export_dominant_frequencies(input_wav_file, output_csv_file)

import numpy as np
import scipy.signal as signal
import scipy.io.wavfile as wavfile
import csv

def export_dominant_frequencies(input_wav, output_csv, prominence_threshold=5.0, width_range=(1, 10)):
    # Load the audio signal
    sample_rate, audio_signal = wavfile.read(input_wav)

    # Perform Fourier Transform to obtain frequency spectrum
    frequencies, amplitudes = signal.welch(audio_signal, fs=sample_rate)

    # Find peaks in the frequency spectrum using find_peaks_cwt
    peak_indices = signal.find_peaks_cwt(amplitudes, widths=np.arange(*width_range))

    if len(peak_indices) > 0:
        dominant_index = peak_indices[np.argmax(amplitudes[peak_indices])]
        dominant_frequency = frequencies[dominant_index]
    else:
        dominant_frequency = None

    # Write the dominant frequency and sample rate to the CSV file
    with open(output_csv, mode='w', newline='') as csvfile:
        csv_writer = csv.writer(csvfile)
        csv_writer.writerow(['DominantFrequency', 'SampleRate'])
        if dominant_frequency is not None:
            csv_writer.writerow([dominant_frequency, sample_rate])
        else:
            csv_writer.writerow(['Not Found', sample_rate])

# Define file paths and parameters
input_wav_file = '/content/TEST.wav'
output_csv_file = 'dominant_frequency.csv'

# Call the function to export the dominant frequency and sample rate
export_dominant_frequencies(input_wav_file, output_csv_file)

import numpy as np
import scipy.signal as signal
import scipy.io.wavfile as wavfile
import matplotlib.pyplot as plt
import csv

def find_and_filter_dominant_frequency(input_wav, output_wav, output_csv, threshold=0.5):
    # Load the audio signal
    sample_rate, audio_signal = wavfile.read(input_wav)

    # Perform Fourier Transform to obtain frequency spectrum
    frequencies, amplitudes = signal.welch(audio_signal, fs=sample_rate)

    # Find the dominant frequency component
    dominant_index = np.argmax(amplitudes)
    dominant_frequency = frequencies[dominant_index]

    # Design a Butterworth notch filter
    nyquist = 0.5 * sample_rate
    notch_width = 10
    low_cutoff = dominant_frequency - notch_width
    high_cutoff = dominant_frequency + notch_width
    q_value = 10

    # Apply the notch filter iteratively
    filtered_audio = audio_signal
    filtered_indices = []

    for i in range(len(filtered_audio)):
        b, a = signal.iirnotch(dominant_frequency / nyquist, Q=q_value)
        filtered_sample = signal.lfilter(b, a, np.array([filtered_audio[i]]))

        if abs(filtered_audio[i] - filtered_sample) < threshold:
            filtered_audio[i] = filtered_sample
            filtered_indices.append(i)

    # Save the filtered audio as a new WAV file
    wavfile.write(output_wav, sample_rate, filtered_audio.astype(np.int16))

    # Write the filtered indices, dominant frequency, and sample rate to CSV
    with open(output_csv, mode='w', newline='') as csvfile:
        csv_writer = csv.writer(csvfile)
        csv_writer.writerow(['Index', 'TimeStamp', 'Frequency', 'SampleRate'])
        for index in filtered_indices:
            timestamp = index / sample_rate
            csv_writer.writerow([index, timestamp, dominant_frequency, sample_rate])

    # Plot the original and filtered audio signals
    plt.figure(figsize=(10, 6))
    plt.plot(audio_signal, label='Original Audio')
    plt.plot(filtered_audio, label='Filtered Audio')
    plt.xlabel('Sample')
    plt.ylabel('Amplitude')
    plt.title('Original vs Filtered Audio')
    plt.legend()
    plt.show()

# Define file paths and parameters
input_wav_file = '/content/AAoutput.wav'
output_wav_file = 'filtered_audio.wav'
output_csv_file = 'filtered_indices.csv'

# Call the function to find and filter the dominant frequency
find_and_filter_dominant_frequency(input_wav_file, output_wav_file, output_csv_file)

import numpy as np
import scipy.signal as signal
import scipy.io.wavfile as wavfile
import matplotlib.pyplot as plt
import csv

def find_and_filter_dominant_frequency(input_wav, output_wav, output_csv, num_iterations=100, threshold=0.5):
    # Load the audio signal
    sample_rate, audio_signal = wavfile.read(input_wav)

    # Perform Fourier Transform to obtain frequency spectrum
    frequencies, amplitudes = signal.welch(audio_signal, fs=sample_rate)

    # Find the dominant frequency component
    dominant_index = np.argmax(amplitudes)
    dominant_frequency = frequencies[dominant_index]

    # Design a Butterworth notch filter
    nyquist = 0.5 * sample_rate
    notch_width = 10
    q_value = 10

    # Iterate and apply the notch filter to suppress the dominant frequency and its harmonics
    filtered_audio = audio_signal
    for _ in range(num_iterations):
        b, a = signal.iirnotch(dominant_frequency / nyquist, Q=q_value)
        filtered_audio = signal.lfilter(b, a, filtered_audio)

    # Save the filtered audio as a new WAV file
    wavfile.write(output_wav, sample_rate, filtered_audio.astype(np.int16))

    # Write the dominant frequency and sample rate to CSV
    with open(output_csv, mode='w', newline='') as csvfile:
        csv_writer = csv.writer(csvfile)
        csv_writer.writerow(['Frequency', 'SampleRate'])
        csv_writer.writerow([dominant_frequency, sample_rate])

    # Plot the original and filtered audio signals
    plt.figure(figsize=(10, 6))
    plt.plot(audio_signal, label='Original Audio')
    plt.plot(filtered_audio, label='Filtered Audio')
    plt.xlabel('Sample')
    plt.ylabel('Amplitude')
    plt.title('Original vs Filtered Audio')
    plt.legend()
    plt.show()

# Define file paths and parameters
input_wav_file = '/content/AAoutput.wav'
output_wav_file = 'filtered_audio.wav'
output_csv_file = 'filtered_frequency.csv'

# Call the function to find and iteratively filter the dominant frequency
find_and_filter_dominant_frequency(input_wav_file, output_wav_file, output_csv_file, num_iterations=10000)

!pip install sounddevice